% !TeX root = ntfs.tex
\section{Recovery}
\label{sec:Recovery}
After being able to store and organize files it would at first glance seem like the file system is finished, but it is actually quite the opposite: there is a lot more than storing files to a file-system. For example in the event of a crash or power loss the file-system should  try to recover from this crash without losing data or worse completely corrupting the volume or its data. In the following section we will look at how NTFS tries to achieve this crash-protection.

\subsection{Atomic Transactions}
% TODO: Intro sentence
Before analyzing how we can log data to use it for recovery, we will look at how NTFS divides up operations that are to be logged. 
The aforementioned data is broken down into so called \textit{atomic transactions}. In order to understand what atomic transactions are it is easiest to look at the two words separately.\\
A \textit{transaction} is a collection of individual disk and file system operations. An example of an operation could be changing the file name in the MFT entry of the file, whereas the transaction containing this operation would probably also need to update the file-index which points to the file in a directory.\\
Another important concept of  transaction is that a transaction is either complete or incomplete. If it is completed it is said to be \textit{committed}.\\ This leads to the concept of committed projections of a set of transactions: A committed projection of these transaction is the result of the application of only the transactions that have successfully completed (and are henceforth committed). Git is again a good analogy here, as the current \texttt{HEAD}-revision is the committed projection of all changes so far in the repository. NTFS makes sure  that only the committed projections are stored. To accomplish this NTFS caches the changes within a transaction on disk and on completion flushes them to their respective locations.\\
The \textit{atomicity} means that no two different transactions executed at any given time rely on each other. Meaning that each transaction is to be only depended on already committed transactions.


\subsection{Journaling}
In order to be able to recover any data when a crash happens we need to know what the file system was doing when the crash happened. To accomplish this the \textit{Log File Service (LFS)} keeps a \textit{journal} of all transactions occurring. The journal itself is a file (so stored in the MFT) and is usually a less than ten megabytes in size. In order to not fill up the journal file and not be able to log any further transactions, the file is written circularly, which means that once the end of the file is reached, the LFS will continue to write to the journal starting again at the beginning of the file. This means that as soon as this condition sets in, old log records will be overwritten \cite{RUSSINOVICH_ET_AL:2012:WI}, except for if the transactions to be overwritten are not yet committed. In this case NTFS will wait until they are, before executing new transactions\cite{active:NTJ}\\.
In this journal NTFS will record all transactions and especially whether they are committed or not. The transactions recorded undo and redo information for the individual operations within the given transactions.
\subsection{Recovery Process}
After discussing how atomic transactions are recorded, we will now analyze how NTFS uses them to ensure the integrity of the file system in case of a crash. Due to the circular writing and the saving of the current position to write to the journal can be read linearly and due to the atomicity of the transactions, they can be dealt with in the order that they were added.
\paragraph{Analyze:}
Once the system is starting again after a crash, the LFS will seek out all the transactions that were active or incomplete at the time of the crash. These transactions might be breaking the invariant of the file system, that specifies that only completed transactions should be stored.
\paragraph{Redo:}
In the redo-phase, NTFS will make sure all committed transactions are flushed.
As NTFS only wants to keep the committed projections of all transactions, it will not always immediately write to the actual target, but rather keep a on-medium cache of the these changes. They are flushed after committing. In case of a crash these caches might not yet have been flushed to their proper locations, even if transactions are commited, as the crash might have happened between the commit and flush. Hence the LFS will redo these operations and flush them to their appropriate location. 
\paragraph{Undo}
In the undo-phase NTFS will make sure all non-committed transactions are reverted.
After the redo is complete, the LFS will undo all uncommitted transaction, with the idea being that the invariant of only keeping the committed projections must be upheld. For this NTFS will undo all operations in the non-committed transactions. Due to the atomicity of transactions this will work without any conflicts.
\subsection{Redundancy Journal and MFT}
In order to ensure that the two studied vital components of NTFS the journal and the MFT survive crashes, NTFS has built-in redundancies. NTFS for one keeps two copies of the MFT and references them in the boot sector such that if one fails the other one can still be used and a new copy can be built. This is a vital measure that is being taken  as without the MFT the file system is unusable and hence all data on it is corrupt. As of such keeping a copy for redundancy prevents corruption through bad disk sector and through write failures. The journal employs a similar system, only  that there are not two copies of the journal, but rather two pointers to the journal. Using the two pointers it can be ensured that the journal is found again\cite{RUSSINOVICH_ET_AL:2012:WI}. As a missing journal does not mean immediate corruption this seems like a good tradeoff between additional storage requirement and redundancy.
With current disk capacities being as large as they, the choice to only keep to pointers, instead of actually storing two copies, seems questionable. The additional storage requirement for another journal is nearly negligible, but the additional fault tolerance could potentially save the file-system, in case one of the copies is corrupt.