% !TeX root = ntfs.tex
\section{Recovery}
After being able to store and organize files it would at first glance seem like the file system is finished, but it is actually quite the opposite: there is a lot more than storing files to a file system. For example in the event of a crash or power loss the file system should make try to recover from this crash without losing data or worse completely corrupting the disk. In the following section we will look at how NTFS tries to achieve this crash-protection.
\subsection{Atomic transactions}
% TODO: Intro sentence
Before analyzing how we can log data to use it for recovery, we will look at how NTFS divides up operations that are to be logged. 
The aforementioned data is broken down into so called \textit{atomic transactions}. In order to understand what atomic transactions are it is easiest to look at the two words separately.
A \textit{transaction} is a collection of individual read and write operations. For example a transaction could be the following
\begin{center}
	\texttt{$ R_1, W_5, R_{42}, W_{42} $}
\end{center}
, where $R_n$  is a read on cluster $n$ and $W_n$ a write on that cluster.\\
Another important concept of these transaction is the committing process. Similar to committing changes in the version control system git, file system changes can be committed in a transaction, once it has been completed. Meaning that a transaction clearly shows that it has completed by committing. This leads to the concept of commited projections of a set of transactions: A committed projection of these transaction is the result of the application of only the transactions that have successfully completed (and are henceforth committed). Git is again a good analogy here, as the current \texttt{HEAD}-revision is the committed projection of all changes so far in the repository. NTFS makes sure  that only the committed projections are stored is that they cache the changes within a transaction on disk and on commit flush them to their respective locations.
The atomicity means that no two different transactions executed at any given rely on each other. Meaning that each transaction is to be only depended of already committed transactions.


\subsection{Journaling}
In order to be able to recover any data when a crash happens we need to know what the file system was doing when the crash happend. In order to do this the \textit{Log File Service (LFS)} keeps a journal of ``everything that happens'', very similar to how us humans would keep a journal of what we do in a day. The journal itself is a file (so stored in the MFT) and is usually a less than ten megabytes in size. In order to not fill up the journal file and not be able log any further transactions, the file is written circularly, which means that once the end of the file is reached, the LFS will continue to write to the journal starting again at the beginning of the file. This means that as soon as this condition sets in, old log records will be overwritten. \cite{RUSSINOVICH_ET_AL:2012:WI}\\
In this journal NTFS will record all transactions and especially whether they are committed or not. The transactions recorded undo and redo information for the individual operations within the given transactions.
\subsection{Recovery Process}
After discussing how atomic transactions are recorded, we will now analyze how NTFS uses them to ensure the integrity of the file system in case of a crash.
\subsection*{Analyze}
Once the system is starting again after a crash, the LFS will seek out all the transactions that were active or incomplete at the time of the crash. These transactions might be breaking the invariant of the file system reflection the committed projection of transactions, as they might not yet be committed or flushed.
\subsection*{Redo}
As NTFS only wants to keep the committed projections of all transactions, it will not always immediately write to the actual target, but rather keep a on-medium cache of the these changes. They are flushed after committing. In case of a crash these caches might not yet have been flushed to their proper locations, as the crash might have happened between the commit and flush. Hence the LFS will redo these operations and the flush them to their appropriate location.
\subsection*{Undo}
After the redo is complete, the LFS will undo all uncommitted transaction, with the idea being that the invariant of only keeping the committed projections must be upheld. For this NTFS will undo all operations in the non-committed transactions. Due to the atomicity of transactions this will work without any conflicts.
\subsection{Redundancy Journal and MFT}
In order to ensure that the two studied vital components of NTFS the Journal and the MFT survive crashes NTFS has some redundancy built in. NTFS for one keeps two copies of the MFT and references them in the boot sector such that if one fails the other one can still be used and a new copy can be built. This is a vital measure that is being taken here as without the MFT the file system is corrupt. As of such keeping a copy for redundancy prevents corruption through bad disk sector and through write failures. The journal employs a similar system, only  that there are not two copies of the journal, but rather two pointers to the journal. Using the two pointers it can be ensured that the journal is found again. As a missing journal does not mean immediate corruption this seems like a good tradeoff between additional storage requirement and redundancy. In my personal opinion, I would argue that keeping two journals does not use up much of the available space on a volume, would improve fault tolerance significantly and would hence be the better idea. That being said the current system has proven to be very reliable. \cite{RUSSINOVICH_ET_AL:2012:WI}